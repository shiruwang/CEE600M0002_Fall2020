{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Autocorrelation and Regression Analysis\n",
    "In this tutorial, you will calculate a global Moran's I statistic to evaluate spatial autocorrelation in your data, and then explore different methods to account for spatial autocorrelation in your data. Specifically, we'll compare parameter estimates relating county income to 2016 county voting preferences using an OLS model, and autoregressive model, and an autocovariance function model.\n",
    "\n",
    "While not entirely environmental in analysis, it is an election year, and this analysis is extremely generalizable to many environmental applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysal as ps\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from libpysal.weights.contiguity import Queen\n",
    "import libpysal\n",
    "from splot.libpysal import plot_spatial_weights\n",
    "from splot.esda import moran_scatterplot\n",
    "from splot.esda import plot_moran\n",
    "from esda.moran import Moran_Local\n",
    "from esda.moran import Moran\n",
    "from statsmodels.api import OLS\n",
    "from pysal.model import spreg\n",
    "sns.set_style('white')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to load the 'Elections' dataset from the libpysal library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.examples import load_example\n",
    "elections = load_example('Elections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on this url to learn more about the variables in this dataset: https://geodacenter.github.io/data-and-lab//county_election_2012_2016-variables/\n",
    "\n",
    "As you can see, there are a lot of data values available in this dataset. We're most interested in seeing whether income (INC910213) factored heavily in the percent change in democratic vote between 2012-2016 for the county (pct_pt_16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's see what files are available in the 'Elections' data example\n",
    "elections.get_file_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll read this shapefile in as a geopandas dataframe (using gpd)\n",
    "#View the shapefile to get a general idea of the geometry that we're working with \n",
    "votes = gpd.read_file(elections.get_path('election.shp'))\n",
    "%matplotlib inline\n",
    "votes.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the first few line]s of the dataset\n",
    "votes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there are too many columns for us to view on a signle page using \"head\", we can just print out hte column names so we have them all listed for reference\n",
    "for col in votes.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use pandas summary statistics to get an idea of how county-level data varies across the united states. For example, how did the county mean percent Democratic vote change between 2012 and 2016?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(votes['pct_dem_12'].mean())\n",
    "print(votes['pct_dem_16'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look here for more info on pandas summary statistics:https://www.earthdatascience.org/courses/intro-to-earth-data-science/scientific-data-structures-python/pandas-dataframes/run-calculations-summary-statistics-pandas-dataframes/\n",
    "\n",
    "We can also plot histograms of the data. Below, smoothed histograms from the seaborn package (imported as sns) let us get an idea of the distribution of percent democratic votes in 2012 and 2016 (right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(2*3*1.6, 2))\n",
    "for i,col in enumerate(['pct_dem_12','pct_dem_16']):\n",
    "    sns.kdeplot(votes[col].values, shade=True, color='slategrey', ax=ax[i])\n",
    "    ax[i].set_title(col.split('_')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the distribution of percent democratic votes changed a bad, mainly the mean shifted to the left. Let's look at this trend in space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(3,2, figsize=(1.6*6 + 1,6*3), gridspec_kw=dict(width_ratios=(6,1)))\n",
    "for i,col in enumerate(['pct_dem_12','pct_dem_16', 'pct_pt_16']):\n",
    "    votes.plot(col, linewidth=.05, cmap='RdBu', ax=ax[i,0])\n",
    "    #ax[i,0].set_title(col.split('_')[1] + ' Two Party Vote (% Dem)')\n",
    "    ax[i,0].set_xticklabels('')\n",
    "    ax[i,0].set_yticklabels('')\n",
    "    sns.kdeplot(votes[col].values, ax=ax[i,1], vertical=True, shade=True, color='slategrey')\n",
    "    ax[i,1].set_xticklabels('')\n",
    "    ax[i,1].set_ylim(-1,1)\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was the county wide percent change in democratic vote related to per capita income?\n",
    "The next question is how can we use robust statistics to determine whether per capita income was related to a chance in 2016 voting preferences. To do this, we're going to conduct a linear regression relating our parameters in pct_pr_16 to INC910213. Then, we're going to use the confidence interval around beta hat (our slope parameter estimate) to determine whether it is significantly different than zero.\n",
    "\n",
    "First we're going to visualize how these variables relate in the global data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes.dropna(subset=['pct_dem_12','pct_dem_16'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(4*2.1,4))\n",
    "votes[['pct_dem_12','pct_dem_16']].plot.scatter('pct_dem_12','pct_dem_16', ax=ax[0])\n",
    "ax[0].set_xlabel('2012 Two Party Vote (% Dem)')\n",
    "ax[0].set_ylabel('2016 Two Party Vote (% Dem)')\n",
    "ax[0].axis([0,1,0,1])\n",
    "r = np.corrcoef(votes['pct_dem_12'].values, votes['pct_dem_16'].values)[0,1]\n",
    "\n",
    "\n",
    "votes[['INC910213','pct_pt_16']].plot.scatter('INC910213','pct_pt_16', ax=ax[1])\n",
    "ax[1].set_xlabel('Per capita income')\n",
    "ax[1].set_ylabel('% Change in Democratic Vote')\n",
    "r = np.corrcoef(votes['pct_pt_16'].values, votes['INC910213'].values)[0,1]\n",
    "\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're looking at in the first plot is the 2012 percent democratic vote and the 2016 percent democratic vote. In the second plot, we're looking at how per capital income (x axis) relates to % change in democratic vote. We want to establish a trendline in the second plot, and determine if the slope in that trendline is statistically significant.\n",
    "\n",
    "### Unmute yourself, or enter into the Zoom chat window, what are some features of this data that it look well-suited for linear regression? What are some features of this data that make it poorly suited for linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do we have spatial autocorrelation in our data?\n",
    "When we're looking at distributions of voting preferences, remember that we're aggregating these numbers over arbitrary (er...political) geographic regions. Each column in that dataframe represents a data value summarized over a US county, but US counties have widely different land areas and populations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(2*3*1.6, 2))\n",
    "sns.kdeplot(votes['ALAND'].values, shade=True, color='slategrey', ax=ax[0])\n",
    "ax[0].set_xlabel('County Land Area')\n",
    "\n",
    "sns.kdeplot(votes['PST045214'].values, shade=True, color='slategrey', ax=ax[1])\n",
    "ax[1].set_xlabel('2014 County Population')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To a certain extent, our data grouping (by county) may not represent an accurate sampling granularity of our spatial or human populuation. First, let's focus on the spatial componnet: the fact that these counties are different sizes. If we want to identify spatial autocorrelation in our data, we need to first understand how this spatial autocorrelation decays as a function of distance. On Tuesday, we calculated the Moran's I statistic, which you can think of as the \"slope\" that we'd get when we regress data values for all geographic entities with data values that neighbor within a given distance. Lets look at our data in lat/lon space again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert coordinate reference system to NAD83 / Conus Albers (EPSG 5070)\n",
    "votes.crs = {'init':'epsg:4326'}\n",
    "votes = votes.to_crs(epsg='5070')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at the data again:\n",
    "votes.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue is that we're sampling spatially at a distinct, and heterogenous, granulatiry. The smallest unit of measurement available in our dataset is the county level. Counties are different sizes. How can we evaluate whether this spatial sampling granularity is of sufficient resolution to capture the scale of variability in our dataset?\n",
    "\n",
    "*If we are sampling at too course of a spatial scale, we run the risk of **missing key patterns of variability in our data** *\n",
    "\n",
    "*If we are sampling at too fine of a sptial scale, we run the risk of **violating assumptions of independence between our individual observations** *\n",
    "\n",
    "## TASK 1: In your own words, describe how the spatial sampling scale of \"county\" might represent and oversampling or undersampling of data as it relates to our question (did per capital income impact change in voting preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating a weights matrix:\n",
    "The first thing we want to tackle is a quantification of any spatial autocorrelation in our dataset. Spatial autocorrelation inflates our theoretical number of samples (N). *When we're calculating test statistics, spatial autocorrelation in our data can make it seem like parameters that are unimportant are actually significant.* \n",
    "\n",
    "Since we're dealing with a heterogeneous sampling grid in our data, the first thing we want to do is calculate a weights matrix.\n",
    "\n",
    "We're going to use the Queen function in pysal to do this. Full documentation here: https://pysal.org/libpysal/generated/libpysal.weights.Queen.html\n",
    "\n",
    "Or just use the built in help with the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??Queen\n",
    "\n",
    "#Click the \"X\" in the upper right corner of that help window that pops up to close it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate weights object\n",
    "weights = Queen.from_dataframe(votes)\n",
    "\n",
    "#Use built in plot function to visualize how the weights matrix works\n",
    "plot_spatial_weights(weights, votes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The verticies in this plot represent two things: first, the identify neigbors based on the model parameters we set for defining neighborhood (here we use the defaul settings and consider any contiguous polygons). It also calculates the distance between those centers (length of the verticies). \"Neighbors\" that are father matter less than \"neighbors\" that are closer in identifying the strength of spatial autocorrelation.\n",
    "\n",
    "## TASK 2: Why did we convert the coordinate reference system?\n",
    "\n",
    "*Double click on this cell and enter answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate Moran and plot\n",
    "moran = Moran(votes['pct_dem_16'], w=weights)\n",
    "plot_moran(moran, zstandard=True, figsize=(10,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Do we have statistically significant evidence (at alpha = 0.05) of spatial autocorrelation in our response variable (Percent change in democratic vote, or pct_pt_16)?\n",
    "\n",
    "*Use code cell below as your \"calculator\". Double click on this cell and enter answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the null hypothesis?\n",
    "# What is the alternative hypothesis?\n",
    "# What is our test statistic?\n",
    "# How can we derive the test statistic from our \"moran\" object?\n",
    "# HINT:\n",
    "?moran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caluculate a linear regression on the global data:\n",
    "In this next step, we're going to calculate a linear regression in our data an determine whether that analysis determines a statistically significant relationship between our percent income and percent change in democratic vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, forumalate the model. See weather_trend.py in \"Git_101\" for a refresher on how.\n",
    "\n",
    "#extract variable that you want to use to \"predict\"\n",
    "X = np.array(votes['PST045214'].values)\n",
    "\n",
    "#extract variable that we want to \"predict\"\n",
    "Y = np.array(votes['pct_dem_16'].values)\n",
    "\n",
    "lm = OLS(Y,X)\n",
    "lm_results = OLS(Y,X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lm_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4: Do we have statistically significant evidence (at alpha = 0.05) of a statistically significant relationship between pct_pt_16 and PST045214? How does PST045214 impact pct_pt_16? Use numbers to back your claim.\n",
    "\n",
    "*Type answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot our residuals to see if there are any spatial patterns in them.\n",
    "\n",
    "Remember residuals = predicted - fitted values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add model residuals to our \"votes\" geopandas dataframe:\n",
    "votes['lm_resid']=lm.fit().resid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, in OLS regression we depend out our residuals being normally distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(votes['lm_resid'].values, shade=True, color='slategrey')\n",
    "ax[1].set_xlabel('OLS residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot them in spac:\n",
    "votes.plot('lm_resid', linewidth=.05, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, these are very *not* normal residuals. What's going on?\n",
    "\n",
    "## TASK 5: What does a positive residual mean here (the model overpredicted change in democratic vote, the model underpredicted change in democratic vote)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we can evaluate whether spatial autocorrelation has impacted our results is if we see spatial autocorrelation in the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Moran and plot\n",
    "moran = Moran(votes['lm_resid'], w=weights)\n",
    "plot_moran(moran, zstandard=True, figsize=(10,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5: Do we have correlated residuals (use numbers to back your answer)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocovariate regression: spatial lag model\n",
    "Let's see if we can get different answers by accounting for our residuals in our model. First, we'll try a spatial lag model. A spatial lag model is a type of autocovariate model that assumes that dependencies exist directly among the levels of the dependent variable, and models them as an \"autocovariate\". So we create an autocovariate function that describes the degree to which the percent change in democratic vote at one location is affected by the percent change in democratic vote at the nearby locations. The coefficient and p-value for the autocovariate function are interpreted as for the independent variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(votes['PST045214'].values).T\n",
    "X.shape = (len(Y),1)\n",
    "Y = np.array(votes['pct_dem_16'].values).T\n",
    "Y.shape = (len(Y),1)\n",
    "\n",
    "lag=spreg.ML_Lag(Y, X, weights)\n",
    "print(lag.summary)\n",
    "#mi = ps.Moran(lag.u, w, two_tailed=False)\n",
    "#pd.Series(index=['Morans I','Z-Score','P-Value'],data=[mi.I, mi.z_norm, mi.p_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add model residuals to our \"votes\" geopandas dataframe:\n",
    "votes['slm_resid']=lag.u\n",
    "sns.kdeplot(votes['slm_resid'].values, shade=True, color='slategrey')\n",
    "ax[1].set_xlabel('SLM residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot them in spac:\n",
    "votes.plot('slm_resid', linewidth=.05, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Moran and plot\n",
    "moran = Moran(votes['slm_resid'], w=weights)\n",
    "plot_moran(moran, zstandard=True, figsize=(10,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6: When we account for spatial autocorrelation in our data using the spatial lag model, do we still see a significant relationship between our response and predictor variable? Do you think this is a valid approach? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial autoregressive model (maximum likelihood spatial error model)\n",
    "Instead of modelling spatial dependence using an autocovariate, we use a similar type of weight structure (here called \"lambda\") to weight the error matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = spreg.ML_Error(Y, X, weights)\n",
    "print(error.summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add model residuals to our \"votes\" geopandas dataframe:\n",
    "votes['mlError_resid']=error.u\n",
    "sns.kdeplot(votes['mlError_resid'].values, shade=True, color='slategrey')\n",
    "ax[1].set_xlabel('MLError residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot them in spac:\n",
    "votes.plot('slm_resid', linewidth=.05, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Moran and plot\n",
    "moran = Moran(votes['slm_resid'], w=weights)\n",
    "plot_moran(moran, zstandard=True, figsize=(10,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 7: Given these three models, do you believe that there is a relationship between percent change in democratic vote and income level? Why or why not?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class_env",
   "language": "python",
   "name": "class_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
